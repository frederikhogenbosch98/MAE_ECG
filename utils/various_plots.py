import matplotlib.pyplot as plt
import numpy as np

def plot_compression_cp():
    R = [5, 10, 15, 20, 25]
    num_params = [6290, 11235, 16180, 21125, 26070]
    full_params = 2881921
    a = [full_params/i for i in num_params]
    plt.plot(R, a)
    plt.title('parameter compression ratio per rank (cp)')
    plt.xlabel('ranks')
    plt.ylabel('compression ratios')
    plt.xticks(R)
    plt.show()

def plot_accs_cp():
    R_LIST = [5, 10, 15, 35, 50, 75, 100, 125, 150]#, 25, 35, 50, 75, 100, 125, 150, 200]
    num_params = [45000, 79000, 1.14e5, 1.48e5, 1.82e5, 2.52e5, 3.55e5, 5.28e5, 7.01e5, 8.73e5]
    full_params = 9411649
    accuracies = [94.28, 94.21, 94.35, 94.35, 94.4, 94.4, 94.48, 94.46, 94.45, 94.43]



    c_ratios = [210.5, 118.8, 82.7, 63.5, 51.5, 37.4, 26.5, 17.8, 13.4, 10.8]#[np.round(full_params / i,1) for i in num_params]
    ticks = list(reversed(c_ratios))
    a = np.arange(len(c_ratios))
    fig, ax = plt.subplots(1, 1,figsize=(10,6))
    # ax.figure() 
    ax.plot(a, accuracies, 'o-', label='CP Accuracies')  
    ax.set_xlabel('Compression ratio')
    ax.set_ylabel('Accuracies')
    ax.tick_params('y')
    ax.set_ylim(93.5, 95.5) 

    ax.axhline(94.51, color='red', linestyle='-', label='Uncompressed baseline')
    # ax.axhline(94.48, color='red', linestyle='-', label='uncompressed')
    ax.set_title('Accuracies at various compression ratios')
    # plt.xticks(c_ratios)
    # ax.set_xlim([205, 1])
    ax.set_xticks(a)
    ax.set_xticklabels(c_ratios)

    ax.legend() 
    plt.show()

def plot_compression_tucker():
    R = [5, 10, 15, 20, 25]
    num_params = [8626, 20621, 37566, 54845, 74300]
    full_params = 2881921
    a = [full_params/i for i in num_params]
    plt.plot(R, a)
    plt.title('parameter compression ratio per rank (tucker)')
    plt.xlabel('ranks')
    plt.ylabel('compression ratios')
    plt.xticks(R)
    plt.show()


def plot_accs_tucker():
    R = [15, 20, 25]
    # num_params = [6290, 11235, 16180, 21125, 26070]
    # full_params = 2881921
    accuracies = [0.895795, 0.903269, 0.902985]
    
    # Calculate compression ratios
    # a = [full_params / i for i in num_params]

    
    plt.plot(R, accuracies, 'o-', label='Accuracies')  # 'r-' is for red solid line
    plt.xlabel('rank')
    plt.ylabel('Accuracies')
    plt.tick_params('y')
    plt.ylim(0.85, 1.0)  # Set the range of the accuracy axis
    
    # Add horizontal lines for literature and 250 epochs benchmarks
    # plt.axhline(0.9439, color='gray', linestyle='-', label='Literature (0.9439)')
    plt.axhline(0.896515, color='red', linestyle='-', label='uncompressed')
    plt.title('CP accuracies with 50 MAE epoch and 25 CLASSIFIER epochs')
    plt.xticks(R)
    plt.legend() 
    plt.show()


def classifier_adam_vs_sgd():
    epoch_adam = np.arange(14)
    epoch_sgd = np.arange(20)

    adam_train_loss_list = [
    0.5779353, 0.1946356, 0.1225612, 0.0946694, 0.0799573,
    0.0701714, 0.0627757, 0.0576435, 0.0539650, 0.0498278,
    0.0477157, 0.0439790, 0.0415124, 0.0389845
    ]
    adam_val_loss_list = [
    1.3850335, 1.1258610, 0.9338873, 0.7984684, 0.6788499,
    0.7822869, 0.8170707, 0.8465877, 0.8286164, 0.9640266,
    0.8102707, 0.8555469, 0.8640891, 0.8114818
    ]
    sgd_val_loss_list = [
    1.8872204, 1.6689397, 1.6294034, 1.4174828, 1.3488336,
    1.3591400, 1.3538532, 1.6205519, 1.2042281, 1.1175311,
    1.0546582, 1.0380862, 1.0226835, 1.0744919, 1.0292719,
    1.0530600, 0.9721900, 0.9735496, 1.0213716, 0.9780238
    ]
    sgd_train_loss_list = [
    1.0305209, 0.7625475, 0.6436381, 0.5631530, 0.5000646,
    0.4512779, 0.4124015, 0.3801628, 0.3540864, 0.3323303,
    0.3133786, 0.2974768, 0.2824948, 0.2718632, 0.2639334,
    0.2542969, 0.2463553, 0.2412917, 0.2379314, 0.2346631 
    ]


    plt.plot(epoch_adam, adam_train_loss_list, label='adam train')
    plt.plot(epoch_adam, adam_val_loss_list, label='adam val')
    plt.plot(epoch_sgd, sgd_val_loss_list, label='sgd train')
    plt.plot(epoch_sgd, sgd_train_loss_list, label='sgd val')
    plt.title('sgd vs adam loss')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.show()


def plot_mses_cp():
    params_un = 722113
    params_cp = [12114, 21539, 30964, 40389, 49814, 191189]
    # num_params = [6290, 11235, 16180, 21125, 26070]
    # full_params = 2881921
    mses = [0.003701, 0.002618, 0.00215, 0.002287, 0.001866, 0.0015]

    print([np.round(params_un / i, 1) for i in params_cp])
    
    # Calculate compression ratios
    # a = [full_params / i for i in num_params]

    R = [np.round(params_un / i, 1) for i in params_cp]
    plt.plot(R, mses, 'o-', label='MSE')  # 'r-' is for red solid line
    plt.xlabel('compression ratio')
    plt.ylabel('Mean Squared Error')
    plt.tick_params('y')
    plt.xlim(70, 0)
    plt.ylim(0.0000, 0.004)  # Set the range of the accuracy axis
    
    # Add horizontal lines for literature and 250 epochs benchmarks
    # plt.axhline(0.9439, color='gray', linestyle='-', label='Literature (0.9439)')
    plt.axhline(0.000204, color='red', linestyle='-', label='uncompressed')
    plt.title('Mean Squared Error (MSE) CPD at various ranks')
    plt.xticks(R)
    plt.legend() 
    plt.show()


def plot_sgd_loss():
    num_epochs = 30
    epochs = np.arange(1, num_epochs+1)
    loss_un = []
    loss_cp = []

    plt.plot(epochs, loss_un, label='uncompressed')
    plt.plot(epochs, loss_cp, label='cpd')
    plt.title('SGD validation loss uncompressed vs cpd')
    plt.xlabel('epochs')
    plt.ylabel('loss')
    plt.legend()
    plt.show()


def plot_adam_loss():
    num_epochs = 25
    epochs = np.arange(1, num_epochs+1)
    loss_un = [0.0238849, 0.0022764, 0.0016823, 0.0008592, 0.0006434,
    0.0005292, 0.0004069, 0.0004447, 0.0004904, 0.0004808,
    0.0002920, 0.0003081, 0.0003146, 0.0002733, 0.0003427,
    0.0003022, 0.0003125, 0.0005739, 0.0003186, 0.0002659,
    0.0002083, 0.0002131, 0.0002058, 0.0002133, 0.0002020]
    #,
    #0.0002014, 0.0002023, 0.0002001, 0.0002032, 0.0002037]
    loss_cp = [0.0098841, 0.0055452, 0.0048496, 0.0054096, 0.0036840,
    0.0034440, 0.0030900, 0.0030042, 0.0028229, 0.0027689,
    0.0029659, 0.0026524, 0.0025764, 0.0025059, 0.0023866,
    0.0024003, 0.0024250, 0.0023358, 0.0025048, 0.0022827,
    0.0021646, 0.0021549, 0.0021544, 0.0021449, 0.0021587]
    #,
    #0.0021498, 0.0021429, 0.0021406, 0.0021506, 0.0021425]


    plt.figure(figsize=(10,6))
    plt.plot(epochs, loss_un, label='Uncompressed')
    plt.plot(epochs, loss_cp, label='CPD')
    plt.title('Adam validation loss uncompressed vs CPD')
    plt.xlabel('epochs')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    plt.show()


def plot_sgd_loss():
    num_epochs = 26
    epochs = np.arange(1, num_epochs+1)
    loss_sgd_un = [
    0.0732750, 0.0407066, 0.0296485, 0.0244884, 0.0216104,
    0.0196357, 0.0182382, 0.0172183, 0.0164245, 0.0157614,
    0.0151992, 0.0147583, 0.0143244, 0.0139463, 0.0136187,
    0.0133186, 0.0130292, 0.0127703, 0.0125228, 0.0122977,
    0.0122899, 0.0122647, 0.0122336, 0.0122135, 0.0122034,
    0.0121941
    ]
    loss_sgd_cp = [
            0.0213847, 0.0170526, 0.0155148, 0.0146263, 0.0139791,
    0.0133995, 0.0129530, 0.0125421, 0.0121045, 0.0117482,
    0.0114239, 0.0111400, 0.0108710, 0.0106306, 0.0104390,
    0.0102340, 0.0100281, 0.0098654, 0.0097105, 0.0095532,
    0.0095301, 0.0095284, 0.0095184, 0.0094924, 0.0094900,
    0.0094835
    ]
    plt.figure(figsize=(10,6))
    plt.plot(epochs, loss_sgd_un, label='Uncompressed')
    plt.plot(epochs, loss_sgd_cp, label='CPD')
    plt.title('SGD validation loss uncompressed vs CPD')
    plt.xlabel('epochs')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    plt.show()


def sgd_vs_adam_loss():
    num_epochs = 26
    epochs = np.arange(1, num_epochs+1)
    loss_sgd = [
    0.0732750, 0.0407066, 0.0296485, 0.0244884, 0.0216104,
    0.0196357, 0.0182382, 0.0172183, 0.0164245, 0.0157614,
    0.0151992, 0.0147583, 0.0143244, 0.0139463, 0.0136187,
    0.0133186, 0.0130292, 0.0127703, 0.0125228, 0.0122977,
    0.0122899, 0.0122647, 0.0122336, 0.0122135, 0.0122034,
    0.0121941
    ]
    loss_adam = [0.0238849, 0.0022764, 0.0016823, 0.0008592, 0.0006434,
    0.0005292, 0.0004069, 0.0004447, 0.0004904, 0.0004808,
    0.0002920, 0.0003081, 0.0003146, 0.0002733, 0.0003427,
    0.0003022, 0.0003125, 0.0005739, 0.0003186, 0.0002659,
    0.0002083, 0.0002131, 0.0002058, 0.0002133, 0.0002020,
    0.0002014]

    plt.figure(figsize=(10,6))
    plt.plot(epochs, loss_sgd, label='SGD')
    plt.plot(epochs, loss_adam, label='Adam')
    plt.title('Val loss: Adam vs SGD for uncompressed model')
    plt.xlabel('epochs')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    plt.show()


def exp1_val_comp():
    epochs = np.arange(30)
    basic_0 = [
    0.00512783, 0.00209671, 0.00132064, 0.00091725, 0.00072729, 0.00065543,
    0.00057368, 0.00046878, 0.00037255, 0.00038711, 0.00035563, 0.00046265,
    0.00029022, 0.00058916, 0.00034564, 0.0002656, 0.00031416, 0.00026493,
    0.00028163, 0.00023158, 0.00035372, 0.00022482, 0.00024224, 0.00022552,
    0.00021913, 0.00023666, 0.00022781, 0.00022489, 0.0002809, 0.0002232
    ]

    basic_1 = []

    unet_32 = [0.004156285646246818, 0.0011023353717064684, 0.0005688073118387171, 0.00039244417829877303, 0.0003974154963578794, 0.0003106951404252221, 0.0001887080951234638, 0.0001250536223704187, 0.00010165926017006884, 0.00013504751243713584, 0.00016782218489477417, 5.959230861464557e-05, 4.919814457997249e-05, 4.739524798115094e-05, 3.952207328018022e-05, 3.551188717333155e-05, 3.441599291555243e-05, 3.391985900831505e-05, 3.195004268699522e-05, 2.720479878681701e-05, 2.8916369627726344e-05, 2.5724034812010238e-05, 2.907274663761749e-05, 2.7934885213083696e-05, 2.5316606748611047e-05, 2.8219989855343788e-05, 2.863914043328831e-05, 3.188875519379306e-05, 2.7872578284595303e-05, 3.0021356200809702e-05

] # 0 was best run

    resnet = [
   0.00675587815199253, 0.004965792203408984, 0.003818188959516905, 0.00332340417598214, 0.002891929206288005, 0.002608530540418482, 0.0025173607808210287, 0.00244503775936831, 0.002238601520662448, 0.0021661529647990377, 0.002048674023120323, 0.0020881279712887456, 0.0019966290931421283, 0.00218796230399786, 0.002435368978105751, 0.0018272909009921876, 0.0018388296560746839, 0.0018340871406580784, 0.0018057202346360185, 0.0018630775735928033, 0.001792644666969602, 0.001818668024655683, 0.0017889776437224783, 0.0018053944919539438, 0.0018314204989765214, 0.0017961857249936743, 0.0017951631499176241, 0.0017857773775950775, 0.0017899234994176252, 0.0018999536194567372

    ]

    convnext = [
            0.4180935, 0.1561054, 0.0555688, 0.0301291, 0.0268757, 0.0267306, 0.0267293,
            0.0267294, 0.0267293, 0.0267293, 0.0267293, 0.0267293, 0.0267295, 0.0267293,
            0.0267293, 0.0267295, 0.0267301, 0.0267293, 0.0267294, 0.0267298, 0.0267294,
            0.0267294, 0.0267297, 0.0267293, 0.0267295, 0.0267294, 0.0267295, 0.0267293,
            0.0267295, 0.0267295
    ]

    

    plt.figure(figsize=(10,6))
    plt.plot(epochs, basic_0, label='Basic')
    plt.plot(epochs, resnet, label='ResNet')
    plt.plot(epochs, convnext, label='ConvNeXt v2')
    plt.plot(epochs, unet_32, label='U-Net')
    plt.title('Validation loss comparison for best run of all models')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.yscale('log')
    plt.legend()
    plt.show()


def train_val_loss(model_name):
    epochs = np.arange(1, 31)
    train_basic = [
    0.02709269, 0.00314659, 0.00157946, 0.00105682, 0.00078327, 0.00063264,
    0.0005262, 0.00045044, 0.00039496, 0.00035943, 0.00037506, 0.00031428,
    0.00030529, 0.00062851, 0.00037853, 0.00026943, 0.000253, 0.00024419,
    0.00023609, 0.00023052, 0.00022686, 0.00022452, 0.00022153, 0.00022049,
    0.00021856, 0.0002181, 0.00021759, 0.00021622, 0.00021523, 0.00021592
    ]


    val_basic = [
    0.00512783, 0.00209671, 0.00132064, 0.00091725, 0.00072729, 0.00065543,
    0.00057368, 0.00046878, 0.00037255, 0.00038711, 0.00035563, 0.00046265,
    0.00029022, 0.00058916, 0.00034564, 0.0002656, 0.00031416, 0.00026493,
    0.00028163, 0.00023158, 0.00035372, 0.00022482, 0.00024224, 0.00022552,
    0.00021913, 0.00023666, 0.00022781, 0.00022489, 0.0002809, 0.0002232
    ]

    train_unet = [
    3.14014199e-02, 1.87287486e-03, 7.04336727e-04, 3.87587307e-04,
    2.53360916e-04, 1.87811141e-04, 1.40537571e-04, 1.14069346e-04,
    8.69331761e-05, 7.10594819e-05, 5.90466023e-05, 7.00930675e-05,
    4.60824481e-05, 4.05830999e-05, 4.72378914e-05, 3.45549996e-05,
    3.28929212e-05, 3.10949877e-05, 2.94418844e-05, 2.82804832e-05,
    2.74157331e-05, 2.67397827e-05, 2.64615129e-05, 2.59655827e-05,
    2.58788641e-05, 2.56806733e-05, 2.57661188e-05, 2.57448276e-05,
    2.58831691e-05, 2.58478541e-05
    ]

    val_unet = [
    4.15628565e-03, 1.10233537e-03, 5.68807312e-04, 3.92444178e-04,
    3.97415496e-04, 3.10695140e-04, 1.88708095e-04, 1.25053622e-04,
    1.01659260e-04, 1.35047512e-04, 1.67822185e-04, 5.95923086e-05,
    4.91981446e-05, 4.73952480e-05, 3.95220733e-05, 3.55118872e-05,
    3.44159929e-05, 3.39198590e-05, 3.19500427e-05, 2.72047988e-05,
    2.89163696e-05, 2.57240348e-05, 2.90727466e-05, 2.79348852e-05,
    2.53166067e-05, 2.82199899e-05, 2.86391404e-05, 3.18887552e-05,
    2.78725783e-05, 3.00213562e-05
    ]   


    train_resnet = [
    0.01196004, 0.00552999, 0.0042077, 0.00343985, 0.00297129, 0.00266368,
    0.00246643, 0.00231471, 0.00221478, 0.00212954, 0.00207497, 0.00201621,
    0.00198097, 0.00195212, 0.00192639, 0.00180378, 0.00179105, 0.00178616,
    0.00177907, 0.00177532, 0.00177429, 0.00176925, 0.00176864, 0.00176502,
    0.00176419, 0.0017576, 0.00175694, 0.00175171, 0.00174975, 0.00174783
    ]

    val_resnet = [
    0.00675588, 0.00496579, 0.00381819, 0.0033234, 0.00289193, 0.00260853,
    0.00251736, 0.00244504, 0.0022386, 0.00216615, 0.00204867, 0.00208813,
    0.00199663, 0.00218796, 0.00243537, 0.00182729, 0.00183883, 0.00183409,
    0.00180572, 0.00186308, 0.00179264, 0.00181867, 0.00178898, 0.00180539,
    0.00183142, 0.00179619, 0.00179516, 0.00178578, 0.00178992, 0.00189995
    ]




    plt.figure(figsize=(10,6))
    plt.plot(epochs, train_basic, label='training')
    plt.plot(epochs, val_basic, label='validation')
    plt.title(f'Training and validation loss {model_name} model')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    # plt.ylim([0.0001, 0.0005])
    plt.show()



def data_eff():
    epochs = np.arange(1, 31)
    run_R0_0 = [
    0.004137262559429386, 0.0038136257145951072, 0.003543536826990444, 0.0038259328171074626, 0.003372363966726124, 0.003393937373672259, 
    0.003445783453928219, 0.0033641385880688905, 0.0037074117580465915, 0.00370418559323562, 0.00410377759154963, 0.003555135775216017, 0.0032587195599897006,
    0.0036983542139690205, 0.003268519899373595, 0.002933192032067522, 0.002959659284607026, 0.0029147590594997184, 0.0029394590479258024, 0.0029148046258759977,
    0.002939442188843911, 0.002922360733618379, 0.002950174493217029, 0.002899121926776655, 0.0029350224408822437
    ]

    run_R0_1 = [
    0.005489248244528489, 0.003916853509065439, 0.0035057602114687498, 0.0034095164097165155, 0.003441763922768795, 0.0032528722645119228, 0.003503281920145371,
    0.003424616384774742, 0.0032211406787518958, 0.0034376862799329827, 0.003255963565325459, 0.003267379638285131, 0.0033781734132561055, 0.003243399604475137,
    0.0033482897709110537, 0.002889171375360724, 0.0028801012528111196, 0.0028696985379180577,
    0.002894563803392773, 0.002874590086509034, 0.0028664879682200337, 0.0028825714683728787, 0.00290047081111616, 0.0029379730251237446, 0.002956182456113899
    ]
    run_R0_2 = [
    0.0041441620600106525, 0.0037233973799980493, 0.003489396133811157, 0.0032444875857106123,
    0.003477010707994673, 0.00331472090039488, 0.0033214611490424784, 0.003445833303409409, 
    0.0035353455016520485, 0.003202794829442174, 0.0031939754466942705, 0.003487489446653516,
    0.0032626820435375454, 0.0033473444699764657, 0.0031415586992124232, 0.002851114628048785,
    0.002859180361794799, 0.002867135126222772, 0.002835718302937833, 0.0029048963589154747,
    0.0028729950091711328, 0.002829648222946712, 0.0029002511096012148, 0.0028346608507530333, 0.0029374231061936183
    ]

    run_R100_0 = [
    0.01923076676921085, 0.026387882327254402, 0.019252361739121402, 0.020342455713206323, 
    0.01586560586725562, 0.014883634382247516, 0.021851661857161923, 0.01825464936766795, 
    0.023862374399908605, 0.030894918121851675, 0.01962140549495428, 0.014937997476165657, 
    0.020959090903390903, 0.02372854583640756, 0.01734931535042424, 0.008741745248296441, 
    0.0075453660654188435, 0.009529207074070026, 0.00669245406057178, 0.007701430363786624,
    0.008943201647905071, 0.0070868904376563385, 0.011300170301063412, 0.0075248100593829645,
    0.010000916133215522
    ]

    run_R100_1 = [
    0.009298980044193491, 0.01928824852861247, 0.021560975216224822, 0.020197363282706174, 0.12387995615164374, 0.02271329326825744,
    0.022022175982571803, 0.01573165975881487, 0.022750516297694787, 0.0224779840614831, 0.023941019415696596, 0.016484165788216026,
    0.014092733400461598, 0.02978495865571172, 0.020982854245087123, 0.00935835122602717, 0.006595593709000179, 0.007545868059275699,
    0.007691927522084065, 0.008470700124052119, 0.007262634600661514, 0.012920210123620154, 0.008687678788280718, 0.009433737639947499, 0.006596483771290628
    ]
    run_R100_2 = [
    0.015921384056006647, 0.01615084069756191, 0.0264159898976788, 0.02251272517379528, 0.021359655657499452, 0.021624271102206428,
    0.02198859969122478, 0.023662443962494614, 0.01613258059740454, 0.029895166316588142, 0.021108276873400285, 0.023184265998863095,
   0.03124006499304609, 0.02633834872448246, 0.08589971408535028, 0.01286219866887331, 0.007154255382185033,
    0.00682363496943235, 0.010768608442514937, 0.008509410945583546, 0.008724379952037778, 0.01070842174370859, 0.011139454737551274, 0.014062766926375654, 0.008573575751655165
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    run_R0_2 = np.array(run_R0_2)
    
    stacked_arrays_R0 = np.vstack((run_R0_0, run_R0_1, run_R0_2))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_R100_0 = np.array(run_R100_0)
    run_R100_1 = np.array(run_R100_1)
    run_R100_2 = np.array(run_R100_2)
    
    stacked_arrays_R100 = np.vstack((run_R100_0, run_R100_1, run_R100_2))
    
    mean_values_R100 = np.mean(stacked_arrays_R100, axis=0)
    std_devs_R100 = np.std(stacked_arrays_R100, axis=0)

    # x_values_R0 = range(len(mean_values_R0))
    
    # # Plot the mean values
    # plt.plot(x_values_R0, mean_values_R0, label='Mean', color='blue')
    
    # # Plot the area representing the standard deviation
    # plt.fill_between(x_x_values_R0values, mean_values - std_devs, mean_values + std_devs, color='blue', alpha=0.2, label='Standard Deviation')

    plt.figure(figsize=(10,6))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Uncompressed')
    plt.errorbar(range(len(mean_values_R100)), mean_values_R100, yerr=std_devs_R100, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label="CPD")
    plt.title(f'Three run average at 0.025 reduction for uncompressed and cp-decomposed')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    # plt.ylim([0.0001, 0.0005])
    plt.show()


def convergence():
    epochs = np.arange(1, 26)
    run_R0_0 = [
    0.00568682892869098, 0.003156195423994627, 0.0019783330450622847, 0.0014890679639215545, 0.001294519365585456, 0.001144713877053519, 0.0008847500161281614, 0.0008677287036572386,
    0.0007147317430209918, 0.0017368846477210105, 0.0006364619836890241, 0.0005407902845198976, 0.0005865713129967894, 0.0006731584076886631,
    0.0007867729927899033, 0.00028481690823983454, 0.00040101706261740913, 0.00031201495916361827, 0.00032992340135574864, 0.00034481598734463536, 0.00035625646570590537,
      0.0003782633927849481, 0.0003192314296169258, 0.00039682578611072947, 0.00033361653488528256
    ]

    run_R0_1 = [
    0.0110079, 0.0037890, 0.0030919, 0.0016506, 0.0014738, 0.0013501, 
    0.0013495, 0.0010727, 0.0008072, 0.0007353, 0.0003996, 0.0003958, 
    0.0007865, 0.0003986, 0.0004025, 0.0003881, 0.0003655, 0.0003382, 
    0.0002839, 0.0003208, 0.0002061, 0.0002405, 0.0002459, 0.0001889, 
    0.0002049

    ]
    run_R0_2 = [
0.005816977487937765, 0.00351014204776546, 0.0020658660883218316, 0.0014564711568978976, 0.0012065911296522858, 0.0013361918484361165, 0.0009283046321940403, 0.0008428323769221987, 0.0008139392905211696, 0.0006981278337121201, 0.0006026518746086284, 0.000590224830277097, 0.000677645554296471, 0.0010564263706483437, 0.0008170386831266957, 0.0002934179655196888, 0.0003349319678100437, 0.0003330590270457252, 0.00035776551128588425, 0.00036571855793342007, 0.00043672537710246325, 0.00036777350651883426, 0.00034011717943752844, 0.00037279581114512176, 0.0003244351400750013
    ]

    run_R100_0 = [
    0.01630191720898658, 0.009912065556221055, 0.008479436013952082, 0.007783000567251593, 0.007352829466313699, 0.006590318989954113,
    0.00611814036843208, 0.006329014875831784, 0.005829324746339616, 0.005781011720225429, 0.0062598770028892605, 0.006013920801369563,
    0.005504401458085147, 0.0072291982843924385, 0.006459119500207431, 0.005090824268808907, 0.005082351501586941, 0.0049652897222670555,
    0.004993230013097503, 0.005035567195722726, 0.004988922181537547, 0.005603838191451836, 0.004968194988819455, 0.005214978867651268, 0.004990574012984347
    ]

    run_R100_1 = [
    0.0134640,
    0.0090321,
    0.0075955,
    0.0068110,
    0.0063761,
    0.0060866,
    0.0057820,
    0.0057011,
    0.0055994,
    0.0055025,
    0.0057354,
    0.0076205,
    0.0069071,
    0.0068299,
    0.0062460,
    0.0050240,
    0.0050361,
    0.0052032,
    0.0052591,
    0.0053761,
    0.0052960,
    0.0051585,
    0.0052893,
    0.0051556,
    0.005221
    ]
    run_R100_2 = [
    0.013483163818922934, 0.009034644240855825, 0.007521951656320445, 0.006928217221875394, 0.006231341310888843, 0.006114583543981772,
    0.00574439396759312, 0.0055601347520652525, 0.005798535073846718, 0.0055416925621471535, 0.007402421087967899, 0.005952374283445763, 0.006600398753378723,
    0.0068001843479086705, 0.006340751044338536, 0.005065614566902384, 0.00486399092039453, 0.0054623800077468355, 0.004849548902566116,
     0.004939754958268729, 0.004943910867295151, 0.005104200388523309, 0.0054492511452865185, 0.005135215495152364, 0.00515666596644155
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    run_R0_2 = np.array(run_R0_2)
    
    stacked_arrays_R0 = np.vstack((run_R0_0, run_R0_1, run_R0_2))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_R100_0 = np.array(run_R100_0)
    run_R100_1 = np.array(run_R100_1)
    run_R100_2 = np.array(run_R100_2)
    
    stacked_arrays_R100 = np.vstack((run_R100_0, run_R100_1, run_R100_2))
    
    mean_values_R100 = np.mean(stacked_arrays_R100, axis=0)
    std_devs_R100 = np.std(stacked_arrays_R100, axis=0)

    # x_values_R0 = range(len(mean_values_R0))
    
    # # Plot the mean values
    # plt.plot(x_values_R0, mean_values_R0, label='Mean', color='blue')
    
    # # Plot the area representing the standard deviation
    # plt.fill_between(x_x_values_R0values, mean_values - std_devs, mean_values + std_devs, color='blue', alpha=0.2, label='Standard Deviation')

    plt.figure(figsize=(10,6))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Uncompressed')
    plt.errorbar(range(len(mean_values_R100)), mean_values_R100, yerr=std_devs_R100, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='CPD')
    plt.title(f'Three run validation loss average for the uncompressed and CP-decomposed model.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    # plt.ylim([0.0001, 0.0005])
    plt.show()


def MSE_conv():
    epochs = np.arange(1, 26)
    mses_1 = [
    0.013427,
    0.009016,
    0.007525,
    0.006782,
    0.00633,
    0.00604,
    0.006236,
    0.006208,
    0.006436,
    0.005603,
    0.006192,
    0.007921,
    0.006378,
    0.00651,
    0.007108,
    0.00503,
    0.004851,
    0.005164,
    0.005063,
    0.004986,
    0.005137,
    0.005431,
    0.005188,
    0.005,
    0.005357
    ]

    mses_2 = [
    0.013407,
    0.00898,
    0.007557,
    0.006777,
    0.006341,
    0.006061,
    0.005759,
    0.005672,
    0.005574,
    0.005479,
    0.005723,
    0.007591,
    0.006877,
    0.006805,
    0.006221,
    0.005003,
    0.005015,
    0.005173,
    0.00523,
    0.005349,
    0.005268,
    0.005134,
    0.005267,
    0.005128,
    0.005221

    ]


    mses_1 = np.array(mses_1)
    mses_2 = np.array(mses_2)
    
    stacked_arrays = np.vstack((mses_1, mses_2))
    
    mean_values_R0 = np.mean(stacked_arrays, axis=0)
    std_devs_R0 = np.std(stacked_arrays, axis=0)

    plt.figure(figsize=(10,6))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Uncompressed')
    plt.title(f'MSE of the test set for saved model at each epoch for a 25 epoch run.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    # plt.yscale('log')
    # plt.ylim([0.0001, 0.0005])
    plt.show()

def data_eff_0025_un():
    epochs = np.arange(1, 26)
    run_R0_0 = [
0.18585793078626328, 0.10652055422586587, 0.07844931489612442, 0.06588304615036633, 0.04962959465970338, 0.041235051906273947, 0.035971795119257494, 0.032904287283621575, 0.027644402219616622, 0.03646529876051285, 0.026593535183597597, 0.023458556970322363, 0.021464776830736707, 0.021246233763492918, 0.020683614822673828, 0.020695415020330194, 0.019879103756630847, 0.019188571080727752, 0.01817287570695087, 0.018040985170809182, 0.0177487940204369, 0.017816194867322683, 0.01755490651336851, 0.017151290016477767, 0.017217007776683155    ]

    run_R0_1 = [
0.17483145060504063, 0.09708518830531095, 0.07157399551580276, 0.058752242733815546, 0.04994264087858605, 0.04149998025453299, 0.035702222574378106, 0.03166551173220646, 0.0279148370490013, 0.028894325606810715, 0.023911526342904624, 0.023021903715243718, 0.022473885711404, 0.022123970878197882, 0.02113316931116687, 0.02040967849570966, 0.020058580100778052, 0.019676390089870804, 0.01913906030220324, 0.018748983890673327, 0.018116129952850293, 0.018001386988924412, 0.018059848661103047, 0.018095386108262355, 0.017639519524492605
    ]

    run_full_0 = [
0.00568682892869098, 0.003156195423994627, 0.0019783330450622847, 0.0014890679639215545, 0.001294519365585456, 0.001144713877053519, 0.0008847500161281614, 0.0008677287036572386, 0.0007147317430209918, 0.0017368846477210105, 0.0006364619836890241, 0.0005407902845198976, 0.0005865713129967894, 0.0006731584076886631, 0.0007867729927899033, 0.00028481690823983454, 0.00040101706261740913, 0.00031201495916361827, 0.00032992340135574864, 0.00034481598734463536, 0.00035625646570590537, 0.0003782633927849481, 0.0003192314296169258, 0.00039682578611072947, 0.00033361653488528256

    ]

    run_full_1 = [
    0.0110079, 0.0037890, 0.0030919, 0.0016506, 0.0014738, 0.0013501, 
    0.0013495, 0.0010727, 0.0008072, 0.0007353, 0.0003996, 0.0003958, 
    0.0007865, 0.0003986, 0.0004025, 0.0003881, 0.0003655, 0.0003382, 
    0.0002839, 0.0003208, 0.0002061, 0.0002405, 0.0002459, 0.0001889, 
    0.0002049
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    
    stacked_arrays_R0 = np.vstack(( run_R0_0, run_R0_0))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_full_0 = np.array(run_full_0)
    run_full_1 = np.array(run_full_1)
    
    stacked_arrays_full = np.vstack((run_full_0, run_full_1))
    
    mean_values_full = np.mean(stacked_arrays_full, axis=0)
    std_devs_full = np.std(stacked_arrays_full, axis=0)

    plt.figure(figsize=(9,7))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Reduced')
    plt.errorbar(range(len(mean_values_full)), mean_values_full, yerr=std_devs_full, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='Full')
    plt.title(f'Three run validation loss average at a 2.5% ratio.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    plt.ylim([0.0001, 1])
    # plt.ylim([0.0001, 0.0005])
    plt.show()



def data_eff_005_un():
    epochs = np.arange(1, 26)
    run_R0_0 = [
0.12212805047133017, 0.06596265055722177, 0.04532163212319172, 0.0329821959245681, 0.022632523364727597, 0.020640315635120757, 0.01671506531888668, 0.01275812768211954, 0.011518084104451294, 0.010185760203422812, 0.009581978332922984, 0.00926615006955778, 0.008906169962963622, 0.008746837111396219, 0.008598542195181066, 0.008566361452236491, 0.008193161286048928, 0.008047881981913878, 0.007886174465784034, 0.00786796494298141, 0.00754580862099501, 0.007440753591430092, 0.007432936501723668, 0.007356523714180619, 0.007361397307707314
    ]
    run_R0_1 = [
0.09398649485201846, 0.08880237395830272, 0.05284576256908186, 0.032159729117770076, 0.038055994747889475, 0.026810169818892324, 0.018250090319246844, 0.01553564014405958, 0.013314778522619452, 0.014097757320315537, 0.011306691940483596, 0.01086446216508049, 0.010792037470165548, 0.010210592402283244, 0.009985664520795967, 0.009674006693633221, 0.009541348984542772, 0.009225421945629947, 0.008993951040951905, 0.008776255771967136, 0.008566924096887639, 0.00858568600735873, 0.008690850505392755, 0.008364766071944139, 0.008372936439184235
    ]

    run_full_0 = [
       0.00568682892869098, 0.003156195423994627, 0.0019783330450622847, 0.0014890679639215545, 0.001294519365585456, 0.001144713877053519, 0.0008847500161281614, 0.0008677287036572386, 0.0007147317430209918, 0.0017368846477210105, 0.0006364619836890241, 0.0005407902845198976, 0.0005865713129967894, 0.0006731584076886631, 0.0007867729927899033, 0.00028481690823983454, 0.00040101706261740913, 0.00031201495916361827, 0.00032992340135574864, 0.00034481598734463536, 0.00035625646570590537, 0.0003782633927849481, 0.0003192314296169258, 0.00039682578611072947, 0.00033361653488528256
 
    ]

    run_full_1 = [
            0.0110079, 0.0037890, 0.0030919, 0.0016506, 0.0014738, 0.0013501, 
    0.0013495, 0.0010727, 0.0008072, 0.0007353, 0.0003996, 0.0003958, 
    0.0007865, 0.0003986, 0.0004025, 0.0003881, 0.0003655, 0.0003382, 
    0.0002839, 0.0003208, 0.0002061, 0.0002405, 0.0002459, 0.0001889, 
    0.0002049
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    
    stacked_arrays_R0 = np.vstack(( run_R0_0, run_R0_0))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_full_0 = np.array(run_full_0)
    run_full_1 = np.array(run_full_1)
    
    stacked_arrays_full = np.vstack((run_full_0, run_full_1))
    
    mean_values_full = np.mean(stacked_arrays_full, axis=0)
    std_devs_full = np.std(stacked_arrays_full, axis=0)


    plt.figure(figsize=(9,7))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Reduced')
    plt.errorbar(range(len(mean_values_full)), mean_values_full, yerr=std_devs_full, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='Full')    
    plt.title(f'Three run validation loss average at a 5% ratio.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    plt.ylim([0.0001, 1])
    # plt.ylim([0.0001, 0.0005])
    plt.show()


def data_eff_01_un():
    epochs = np.arange(1, 26)
    run_R0_0 = [
0.04707723381132482, 0.025145185358070612, 0.016216791536661838, 0.018558013935440276, 0.011365132486141087, 0.008429608006736462, 0.008731366433386463, 0.007247533302462065, 0.006411573577562297, 0.006021304605068968, 0.005381491346218322, 0.0053582562598813045, 0.005236253810649127, 0.0051879926624527305, 0.00501588810711476, 0.004893412520846009, 0.0048180504913306645, 0.004663182266952903, 0.004676631597909262, 0.0044193372289695575, 0.004344737811883698, 0.0043196818933834156, 0.004316926937260826, 0.004228633666705431, 0.004245956242379001    ]

    run_R0_1 = [
0.05860566535858044, 0.048053953428393595, 0.02890451558051211, 0.013735273400889984, 0.01555313701743197, 0.008778233925984336, 0.007866253738588841, 0.007119727745346139, 0.0065227548791723985, 0.00609981893795361, 0.005453560820703743, 0.005388066791699978, 0.005212024286922283, 0.005195181919808816, 0.004973293053228516, 0.004955823826726026, 0.004770324524594991, 0.004584594224361213, 0.004640091507474033, 0.004371389637429021, 0.004461514058347763, 0.004291501559108564, 0.004400568760301266, 0.004336093463188624, 0.004244486005172817    ]

    run_full_0 = [
0.00568682892869098, 0.003156195423994627, 0.0019783330450622847, 0.0014890679639215545, 0.001294519365585456, 0.001144713877053519, 0.0008847500161281614, 0.0008677287036572386, 0.0007147317430209918, 0.0017368846477210105, 0.0006364619836890241, 0.0005407902845198976, 0.0005865713129967894, 0.0006731584076886631, 0.0007867729927899033, 0.00028481690823983454, 0.00040101706261740913, 0.00031201495916361827, 0.00032992340135574864, 0.00034481598734463536, 0.00035625646570590537, 0.0003782633927849481, 0.0003192314296169258, 0.00039682578611072947, 0.00033361653488528256

    ]

    run_full_1 = [
            0.0110079, 0.0037890, 0.0030919, 0.0016506, 0.0014738, 0.0013501, 
    0.0013495, 0.0010727, 0.0008072, 0.0007353, 0.0003996, 0.0003958, 
    0.0007865, 0.0003986, 0.0004025, 0.0003881, 0.0003655, 0.0003382, 
    0.0002839, 0.0003208, 0.0002061, 0.0002405, 0.0002459, 0.0001889, 
    0.0002049
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    
    stacked_arrays_R0 = np.vstack(( run_R0_0, run_R0_0))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_full_0 = np.array(run_full_0)
    run_full_1 = np.array(run_full_1)
    
    stacked_arrays_full = np.vstack((run_full_0, run_full_1))
    
    mean_values_full = np.mean(stacked_arrays_full, axis=0)
    std_devs_full = np.std(stacked_arrays_full, axis=0)
    
    plt.figure(figsize=(9,7))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Reduced')
    plt.errorbar(range(len(mean_values_full)), mean_values_full, yerr=std_devs_full, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='Full')  
    plt.title(f'Three run validation loss average at a 10% ratio.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    plt.ylim([0.0001, 1])
    # plt.ylim([0.0001, 0.0005])
    plt.show()


def data_eff_02_un():
    epochs = np.arange(1, 26)
    run_R0_0 = [
0.021793207666649782, 0.016384371348938723, 0.007687827909235827, 0.006224550467080277, 0.005200445080300231, 0.005509571533247898, 0.004105175818070296, 0.003764936309898991, 0.0032944145490311065, 0.003003228075797745, 0.0027114478189109014, 0.002692538071942958, 0.002554776356006065, 0.0025054682220010615, 0.0025083372051214452, 0.0023990850897415675, 0.0023091008405736087, 0.002225579845143623, 0.0021857290261607723, 0.0021351404221429692, 0.002002666684225825, 0.0019828499661958257, 0.001978054419049725, 0.0019708491301510555, 0.0019511260760973366
    ]

    run_R0_1 = [
0.036094355168799545, 0.013648859774997616, 0.009172379569378853, 0.006999212834258072, 0.0059963429216937925, 0.005728697186309635, 0.004684109366450077, 0.004638467811681965, 0.0036114467825587217, 0.003368016708254598, 0.003087977225768284, 0.002894988990637334, 0.0028023988022624143, 0.002738891543659399, 0.0026721665453688886, 0.0025385774692291774, 0.0026455338086505114, 0.0024142528210394183, 0.0023308720169388773, 0.0024142838449557635, 0.0021511309539482895, 0.002147344094744468, 0.002129772408797385, 0.0021118619687569037, 0.0020750221243086625

    ]

    run_full_0 = [
0.00568682892869098, 0.003156195423994627, 0.0019783330450622847, 0.0014890679639215545, 0.001294519365585456, 0.001144713877053519, 0.0008847500161281614, 0.0008677287036572386, 0.0007147317430209918, 0.0017368846477210105, 0.0006364619836890241, 0.0005407902845198976, 0.0005865713129967894, 0.0006731584076886631, 0.0007867729927899033, 0.00028481690823983454, 0.00040101706261740913, 0.00031201495916361827, 0.00032992340135574864, 0.00034481598734463536, 0.00035625646570590537, 0.0003782633927849481, 0.0003192314296169258, 0.00039682578611072947, 0.00033361653488528256

    ]

    run_full_1 = [
            0.0110079, 0.0037890, 0.0030919, 0.0016506, 0.0014738, 0.0013501, 
    0.0013495, 0.0010727, 0.0008072, 0.0007353, 0.0003996, 0.0003958, 
    0.0007865, 0.0003986, 0.0004025, 0.0003881, 0.0003655, 0.0003382, 
    0.0002839, 0.0003208, 0.0002061, 0.0002405, 0.0002459, 0.0001889, 
    0.0002049
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    
    stacked_arrays_R0 = np.vstack(( run_R0_0, run_R0_0))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_full_0 = np.array(run_full_0)
    run_full_1 = np.array(run_full_1)
    
    stacked_arrays_full = np.vstack((run_full_0, run_full_1))
    
    mean_values_full = np.mean(stacked_arrays_full, axis=0)
    std_devs_full = np.std(stacked_arrays_full, axis=0)


    plt.figure(figsize=(9,7))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Reduced')
    plt.errorbar(range(len(mean_values_full)), mean_values_full, yerr=std_devs_full, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='Full')   
    plt.title(f'Three run validation loss average at a 20% ratio.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    plt.ylim([0.0001, 1])
    # plt.ylim([0.0001, 0.0005])
    plt.show()


def data_eff_0025_cp():
    epochs = np.arange(1, 26)
    run_R0_0 = [
0.21260079158677384, 0.17589802426424728, 0.14475460695621453, 0.1265029964319903, 0.11811670842077943, 0.1019776950935475, 0.09249873926085708, 0.07581994963174278, 0.06702909184940568, 0.06128646457567702, 0.05872883401240015, 0.057631942694254666, 0.056873477123681654, 0.05550550383375988, 0.053942634020830306, 0.0532254001439061, 0.0526720672117667, 0.0504055305254793, 0.04950313443169561, 0.049550420298859144, 0.048401854892823656, 0.04860859642146363, 0.048834115475129974, 0.04737852363639793, 0.04709687339278416
    ]
    run_R0_1 = [
0.2217566000681931, 0.1750154065307119, 0.1560437625251484, 0.1356442055816623, 0.13138519961960862, 0.12306541533635805, 0.11186794344737838, 0.10313221565349855, 0.09133036927138292, 0.08293590952558876, 0.08019992531108558, 0.07687376827828783, 0.0768788489782783, 0.07340650307262726, 0.07215598439290023, 0.0717783824700958, 0.06838596052494374, 0.06696601785444967, 0.06551583588940063, 0.06335525840883854, 0.06324455822158796, 0.06344373716288933, 0.06306835285738549, 0.062209383259247776, 0.06277305464115049
    ]

    run_full_0 = [
0.01630191720898658, 0.009912065556221055, 0.008479436013952082, 0.007783000567251593, 0.007352829466313699, 0.006590318989954113, 0.00611814036843208, 0.006329014875831784, 0.005829324746339616, 0.005781011720225429, 0.0062598770028892605, 0.006013920801369563, 0.005504401458085147, 0.0072291982843924385, 0.006459119500207431, 0.005090824268808907, 0.005082351501586941, 0.0049652897222670555, 0.004993230013097503, 0.005035567195722726, 0.004988922181537547, 0.005603838191451836, 0.004968194988819455, 0.005214978867651268, 0.004990574012984347
    ]

    run_full_1 = [
    0.013464036938094255, 0.00903210825352086, 0.0075955374812683414, 0.0068110281427521705, 0.0063761358432994865, 0.0060866124461272835, 0.005782005093359567, 0.0057010596124008675, 0.005599419191433218, 0.005502544572143751, 0.005735415603086172, 0.007620516565110851, 0.006907086190139051, 0.006829896669043198, 0.006246022825677042, 0.005023964014974997, 0.005036077302317058, 0.005203174053084716, 0.005259136967380606, 0.00537608761908979, 0.0052959907801268065, 0.005158513293742222, 0.00528925497359939, 0.00515558729502328, 0.0052446635484057575
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    
    stacked_arrays_R0 = np.vstack(( run_R0_0, run_R0_0))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_full_0 = np.array(run_full_0)
    run_full_1 = np.array(run_full_1)
    
    stacked_arrays_full = np.vstack((run_full_0, run_full_1))
    
    mean_values_full = np.mean(stacked_arrays_full, axis=0)
    std_devs_full = np.std(stacked_arrays_full, axis=0)

    plt.figure(figsize=(9,7))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Reduced')
    plt.errorbar(range(len(mean_values_full)), mean_values_full, yerr=std_devs_full, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='Full')
    plt.title(f'Three run validation loss average at a 2.5% ratio.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    # plt.ylim([0.0001, 0.0005])
    plt.ylim([0.0001, 1])
    plt.show()



def data_eff_005_cp():
    epochs = np.arange(1, 26)
    run_R0_0 = [
0.1895564476709466, 0.12702552915673532, 0.10814193058613907, 0.08554420918671261, 0.06855139012319837, 0.05458577742729546, 0.04484889755889258, 0.03769431274072092, 0.031346013548852074, 0.02734299870021936, 0.02617858699944208, 0.025853344210444634, 0.02462314321710388, 0.02380350498186887, 0.023259904614958447, 0.022655888040044335, 0.022154787766721053, 0.021885073086648346, 0.02104355112340332, 0.020941003395734546, 0.020544190733421567, 0.020218051330944432, 0.02011220395569832, 0.020325173297021666, 0.019847741857395313
    ]
    run_R0_1 = [
0.1925614006307314, 0.1427568495221235, 0.1390130975374595, 0.11544206782232203, 0.09205388898134524, 0.07076036289431155, 0.05938681573942701, 0.045511378308345514, 0.038183879824284894, 0.03098645524783405, 0.028942753549006627, 0.027878386219429518, 0.027504017871073254, 0.026105133861210834, 0.02503814158087827, 0.024296767777881815, 0.023525555522613623, 0.022870917175349736, 0.022207443643885535, 0.021662343184900464, 0.021950324809699752, 0.02122229291619689, 0.021625029188529273, 0.021381986357300903, 0.020766931005861067
    ]

    run_full_0 = [
0.01630191720898658, 0.009912065556221055, 0.008479436013952082, 0.007783000567251593, 0.007352829466313699, 0.006590318989954113, 0.00611814036843208, 0.006329014875831784, 0.005829324746339616, 0.005781011720225429, 0.0062598770028892605, 0.006013920801369563, 0.005504401458085147, 0.0072291982843924385, 0.006459119500207431, 0.005090824268808907, 0.005082351501586941, 0.0049652897222670555, 0.004993230013097503, 0.005035567195722726, 0.004988922181537547, 0.005603838191451836, 0.004968194988819455, 0.005214978867651268, 0.004990574012984347
    ]

    run_full_1 = [
    0.013464036938094255, 0.00903210825352086, 0.0075955374812683414, 0.0068110281427521705, 0.0063761358432994865, 0.0060866124461272835, 0.005782005093359567, 0.0057010596124008675, 0.005599419191433218, 0.005502544572143751, 0.005735415603086172, 0.007620516565110851, 0.006907086190139051, 0.006829896669043198, 0.006246022825677042, 0.005023964014974997, 0.005036077302317058, 0.005203174053084716, 0.005259136967380606, 0.00537608761908979, 0.0052959907801268065, 0.005158513293742222, 0.00528925497359939, 0.00515558729502328, 0.0052446635484057575
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    
    stacked_arrays_R0 = np.vstack(( run_R0_0, run_R0_0))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_full_0 = np.array(run_full_0)
    run_full_1 = np.array(run_full_1)
    
    stacked_arrays_full = np.vstack((run_full_0, run_full_1))
    
    mean_values_full = np.mean(stacked_arrays_full, axis=0)
    std_devs_full = np.std(stacked_arrays_full, axis=0)


    plt.figure(figsize=(9,7))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Reduced')
    plt.errorbar(range(len(mean_values_full)), mean_values_full, yerr=std_devs_full, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='Full')    
    plt.title(f'Three run validation loss average at a 5% ratio.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    # plt.ylim([0.0001, 0.0005])
    plt.ylim([0.0001, 1])
    plt.show()


def data_eff_01_cp():
    epochs = np.arange(1, 26)
    run_R0_0 = [
0.14387988847508434, 0.12093461282041262, 0.07418047939273131, 0.04837612577824135, 0.034036289465993186, 0.027539424331096442, 0.022216454630942, 0.019575686539056086, 0.01833173275832016, 0.016722665061507654, 0.01585872141265765, 0.015717574269532346, 0.015445712635639038, 0.01501672187971798, 0.014745879291710624, 0.014455205804525535, 0.014300279503183971, 0.014013459647587314, 0.013703767627777816, 0.013821415876880364, 0.013649099378113013, 0.013442362675749461, 0.013599155915748035, 0.013384149444079594, 0.013254384078016051
    ]
    run_R0_1 = [
0.10444676542914555, 0.07771580288648158, 0.047166988786525706, 0.03174620000493361, 0.024017321118522027, 0.019579341532797216, 0.016678042553089058, 0.014602867880425032, 0.013143277103986108, 0.012146262129367449, 0.011490835360416994, 0.011331810235945323, 0.01112668718832907, 0.010954318205387129, 0.010772506552023317, 0.010624266778426877, 0.010463522544009939, 0.01031903523922101, 0.01017407833210744, 0.010043779724506773, 0.00996493489844232, 0.009928435641896367, 0.00989167800455336, 0.009867776424471923, 0.009832957355055665
    ]
    run_full_0 = [
0.01630191720898658, 0.009912065556221055, 0.008479436013952082, 0.007783000567251593, 0.007352829466313699, 0.006590318989954113, 0.00611814036843208, 0.006329014875831784, 0.005829324746339616, 0.005781011720225429, 0.0062598770028892605, 0.006013920801369563, 0.005504401458085147, 0.0072291982843924385, 0.006459119500207431, 0.005090824268808907, 0.005082351501586941, 0.0049652897222670555, 0.004993230013097503, 0.005035567195722726, 0.004988922181537547, 0.005603838191451836, 0.004968194988819455, 0.005214978867651268, 0.004990574012984347
    ]

    run_full_1 = [
    0.013464036938094255, 0.00903210825352086, 0.0075955374812683414, 0.0068110281427521705, 0.0063761358432994865, 0.0060866124461272835, 0.005782005093359567, 0.0057010596124008675, 0.005599419191433218, 0.005502544572143751, 0.005735415603086172, 0.007620516565110851, 0.006907086190139051, 0.006829896669043198, 0.006246022825677042, 0.005023964014974997, 0.005036077302317058, 0.005203174053084716, 0.005259136967380606, 0.00537608761908979, 0.0052959907801268065, 0.005158513293742222, 0.00528925497359939, 0.00515558729502328, 0.0052446635484057575
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    
    stacked_arrays_R0 = np.vstack(( run_R0_0, run_R0_0))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_full_0 = np.array(run_full_0)
    run_full_1 = np.array(run_full_1)
    
    stacked_arrays_full = np.vstack((run_full_0, run_full_1))
    
    mean_values_full = np.mean(stacked_arrays_full, axis=0)
    std_devs_full = np.std(stacked_arrays_full, axis=0)
    
    plt.figure(figsize=(9,7))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Reduced')
    plt.errorbar(range(len(mean_values_full)), mean_values_full, yerr=std_devs_full, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='Full')  
    plt.title(f'Three run validation loss average at a 10% ratio.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.yscale('log')
    # plt.ylim([0.0001, 0.0005])
    plt.ylim([0.0001, 1])
    plt.show()


def data_eff_02_cp():
    epochs = np.arange(1, 26)
    run_R0_0 = [
0.06456576165846083, 0.03143746541778003, 0.022299871505822477, 0.017928319834026568, 0.014831872732910983, 0.013128588966538377, 0.012421157614363907, 0.011260952446514842, 0.010645095205996088, 0.010454885224708822, 0.009873614747387212, 0.009915637997489903, 0.009648067518227109, 0.009395926704150006, 0.009324695739702918, 0.009278818609869986, 0.009187444998052281, 0.009145957570870531, 0.008998734622372637, 0.008991908090672403, 0.008858775476657681, 0.008741171399469871, 0.008767452541887743, 0.008830923320781297, 0.008722590853612782    ]

    run_R0_1 = [
0.09712860282928706, 0.04267182152107713, 0.023713272277835366, 0.017086729746855742, 0.01376192848014709, 0.011678303143724738, 0.010479977859962165, 0.009706740006998617, 0.00921214915055701, 0.008893531496021014, 0.008369011609656522, 0.008258540234079372, 0.008177869163360649, 0.00807024610161811, 0.007998775362728701, 0.007910826035648228, 0.007832914059212192, 0.007778785203392606, 0.007695778150202186, 0.007658946694651443, 0.007581188283256854, 0.007560420152975291, 0.007541957671683219, 0.007525261783799065, 0.007505505477931376

    ]

    run_full_0 = [
0.01630191720898658, 0.009912065556221055, 0.008479436013952082, 0.007783000567251593, 0.007352829466313699, 0.006590318989954113, 0.00611814036843208, 0.006329014875831784, 0.005829324746339616, 0.005781011720225429, 0.0062598770028892605, 0.006013920801369563, 0.005504401458085147, 0.0072291982843924385, 0.006459119500207431, 0.005090824268808907, 0.005082351501586941, 0.0049652897222670555, 0.004993230013097503, 0.005035567195722726, 0.004988922181537547, 0.005603838191451836, 0.004968194988819455, 0.005214978867651268, 0.004990574012984347
    ]

    run_full_1 = [
    0.013464036938094255, 0.00903210825352086, 0.0075955374812683414, 0.0068110281427521705, 0.0063761358432994865, 0.0060866124461272835, 0.005782005093359567, 0.0057010596124008675, 0.005599419191433218, 0.005502544572143751, 0.005735415603086172, 0.007620516565110851, 0.006907086190139051, 0.006829896669043198, 0.006246022825677042, 0.005023964014974997, 0.005036077302317058, 0.005203174053084716, 0.005259136967380606, 0.00537608761908979, 0.0052959907801268065, 0.005158513293742222, 0.00528925497359939, 0.00515558729502328, 0.0052446635484057575
    ]

    run_R0_0 = np.array(run_R0_0)
    run_R0_1 = np.array(run_R0_1)
    
    stacked_arrays_R0 = np.vstack(( run_R0_0, run_R0_0))
    
    mean_values_R0 = np.mean(stacked_arrays_R0, axis=0)
    std_devs_R0 = np.std(stacked_arrays_R0, axis=0)

    run_full_0 = np.array(run_full_0)
    run_full_1 = np.array(run_full_1)
    
    stacked_arrays_full = np.vstack((run_full_0, run_full_1))
    
    mean_values_full = np.mean(stacked_arrays_full, axis=0)
    std_devs_full = np.std(stacked_arrays_full, axis=0)


    plt.figure(figsize=(9,7))
    plt.errorbar(range(len(mean_values_R0)), mean_values_R0, yerr=std_devs_R0, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Reduced')
    plt.errorbar(range(len(mean_values_full)), mean_values_full, yerr=std_devs_full, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='Full')   
    plt.title(f'Three run validation loss average at a 20% ratio.')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.ylim([0.0001, 0.1])
    plt.yscale('log')
    # plt.ylim([0.0001, 0.0005])
    plt.ylim([0.0001, 1])
    plt.show()


def exp2_3_mses():
    mses_un_0 = [0.0173, 0.00742, 0.004198, 0.001965]
    mses_un_1 = [0.0177, 0.00845, 0.004196, 0.002088]
    
    mses_cp_0 = [0.0468, 0.019795, 0.013432, 0.008604]
    mses_cp_1 = [0.062448, 0.020724, 0.009969, 0.007387]

    mses_un_0 = np.array(mses_un_0)
    mses_un_1 = np.array(mses_un_1)
    
    stacked_arrays_UN = np.vstack(( mses_un_1, mses_un_0))
    
    mean_values_UN = np.mean(stacked_arrays_UN, axis=0)
    std_devs_UN = np.std(stacked_arrays_UN, axis=0)

    mses_cp_0 = np.array(mses_cp_0)
    mses_cp_1 = np.array(mses_cp_1)
    
    stacked_arrays_CP = np.vstack((mses_cp_0, mses_cp_1))
    
    mean_values_CP = np.mean(stacked_arrays_CP, axis=0)
    std_devs_CP = np.std(stacked_arrays_CP, axis=0)

    a = np.arange(4)
    c_ratios = [0.025, 0.05, 0.1, 0.2]

    fig, ax = plt.subplots(1, 1,figsize=(10,6))
    ax.errorbar(range(len(mean_values_UN)), mean_values_UN, yerr=std_devs_UN, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Uncompressed reduced')
    ax.errorbar(range(len(mean_values_CP)), mean_values_CP, yerr=std_devs_CP, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='CPD reduced')   
    ax.axhline(y=0.000206, color='red', linestyle='--', label='Uncompressed full')
    ax.axhline(y=0.004702, color='green', linestyle='--', label='CPD full')
    ax.set_title(f'MSE of the test set comparison at every training set ratio.')
    ax.set_xlabel('reduction rate')
    ax.set_ylabel('loss')
    ax.set_xticks(a)
    ax.set_xticklabels(c_ratios)
    # plt.xticks()
    ax.set_yscale('log')
    ax.legend()
    plt.show()



def exp2_3_accs():
    accs_un_0 = [92.031, 93.21, 93.22, 94.12]
    accs_un_1 = [92.51, 93.04, 92.9, 93.69]
    
    accs_cp_0 = [91.46, 92.668, 93.415, 94.07]
    accs_cp_1 = [92.142, 92.93, 93.977, 93.68]

    accs_un_0 = np.array(accs_un_0)
    accs_un_1 = np.array(accs_un_1)
    
    stacked_arrays_UN = np.vstack(( accs_un_1, accs_un_0))
    
    mean_values_UN = np.mean(stacked_arrays_UN, axis=0)
    std_devs_UN = np.std(stacked_arrays_UN, axis=0)

    accs_cp_0 = np.array(accs_cp_0)
    accs_cp_1 = np.array(accs_cp_1)
    
    stacked_arrays_CP = np.vstack((accs_cp_0, accs_cp_1))
    
    mean_values_CP = np.mean(stacked_arrays_CP, axis=0)
    std_devs_CP = np.std(stacked_arrays_CP, axis=0)

    a = np.arange(4)
    c_ratios = [0.025, 0.05, 0.1, 0.2]

    # plt.figure(figsize=(10,6))
    # plt.errorbar(range(len(mean_values_UN)), mean_values_UN, yerr=std_devs_UN, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Uncompressed reduced')
    # # plt.errorbar(range(len(mean_values_CP)), mean_values_CP, yerr=std_devs_CP, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='CPD reduced')   
    # plt.axhline(y=94.48, color='red', linestyle='--', label='Uncompressed full')
    # # plt.axhline(y=94.48, color='green', linestyle='--', label='CPD full')
    # plt.title(f'MSE of the test set comparison at every trainin set ratio.')
    # plt.xlabel('epoch')
    # plt.ylabel('accuracy')
    # plt.legend()
    # plt.show()


    # plt.figure(figsize=(10,6))

    # # plt.errorbar(range(len(mean_values_UN)), mean_values_UN, yerr=std_devs_UN, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Uncompressed reduced')
    # plt.errorbar(range(len(mean_values_CP)), mean_values_CP, yerr=std_devs_CP, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='CPD reduced')   
    # # plt.axhline(y=94.48, color='red', linestyle='--', label='Uncompressed full')
    # plt.axhline(y=94.48, color='green', linestyle='--', label='CPD full')
    # plt.title(f'MSE of the test set comparison at every trainin set ratio.')
    # plt.xlabel('epoch')
    # plt.ylabel('accuracy')
    # plt.legend()
    # plt.show()

    fig, ax = plt.subplots(1, 1,figsize=(10,6))
    ax.errorbar(range(len(mean_values_UN)), mean_values_UN, yerr=std_devs_UN, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Uncompressed reduced')
    ax.errorbar(range(len(mean_values_CP)), mean_values_CP, yerr=std_devs_CP, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='CPD reduced')   
    ax.axhline(y=94.48, color='red', linestyle='--', label='Uncompressed and CPD full')
    # ax.axhline(y=94.48, color='green', linestyle='--', label='CPD full')
    ax.set_title(f'MSE of the test set at every training set ratio.')
    ax.set_xlabel('reduction rate')
    ax.set_ylabel('loss')
    ax.set_xticks(a)
    ax.set_xticklabels(c_ratios)
    # plt.xticks()
    # ax.set_yscale('log')
    ax.legend()
    plt.show()


def exp2_2_SGD():
    mses_un_0 = [0.017050223682334678, 0.014953739314221219, 0.013711551772704859, 0.01272776848609572, 0.011916292869859109, 0.011250459058149719, 0.010694211506829431, 0.010242669900346222, 0.009860731213628276, 0.009549308382814562, 0.00947168208929197, 0.009408817902764086, 0.009337328092867586, 0.009273910664899791, 0.009219258945842565, 0.009155405651874622, 0.009098312706204616, 0.009043977431383155, 0.008987921996731148, 0.008939430120770243, 0.008921725001717756, 0.008913870884235687, 0.008905076645343053, 0.008894971810296984, 0.008875513731320336]
    mses_un_1 = [0.017147058651480383, 0.015109229322206348, 0.013999852576044528, 0.013112903807726511, 0.01235124972564005, 0.011671997307838858, 0.011069831131484803, 0.010548060417902594, 0.010117778023262594, 0.00974921221473621, 0.009668460697696548, 0.009591013402442202, 0.009518383375250176, 0.009445494228562015, 0.009372173597567264, 0.009304918993848851, 0.009247132051923068, 0.009186753479887882, 0.009124361304732601, 0.009060376152568975, 0.009054821213655955, 0.009039056121167774, 0.009026646809697713, 0.009015995399936892, 0.008998820422884888]
    
    mses_cp_0 = [0.08782392359801881, 0.04543010763893357, 0.03185393373045254, 0.02656660283787919, 0.0240651256030532, 0.022565336305373877, 0.02153019388298743, 0.02078234133420071, 0.020171583782792712, 0.01968820311149599, 0.019569523870960684, 0.01950067810357793, 0.01936310179507142, 0.019292291037621832, 0.01919793578722846, 0.01909971947588082, 0.019025857502255043, 0.01894192581830203, 0.018867780630228467, 0.01879759697043858, 0.01875619806280343, 0.018745917129803332, 0.018714960435783967, 0.01869908212344059, 0.018714536626585412]
    mses_cp_1 = [0.05936116333262294, 0.030260780491464946, 0.024424998463465415, 0.022387467843922756, 0.021349561834114388, 0.020584453950958564, 0.02003291031979332, 0.01958905359213226, 0.019233317468301182, 0.018956578136124787, 0.018887721880142153, 0.018836470517589084, 0.01878196250667158, 0.018720820741936824, 0.018661157721336724, 0.0186083745055388, 0.018550825815364467, 0.018506998036669966, 0.018452464092697157, 0.01840019678783049, 0.01839317393336425, 0.018374488178923978, 0.018368510436795667, 0.01835256843839281, 0.01833960357770946]

    mses_un_0 = np.array(mses_un_0)
    mses_un_1 = np.array(mses_un_1)
    
    stacked_arrays_UN = np.vstack(( mses_un_1, mses_un_0))
    
    mean_values_UN = np.mean(stacked_arrays_UN, axis=0)
    std_devs_UN = np.std(stacked_arrays_UN, axis=0)

    mses_cp_0 = np.array(mses_cp_0)
    mses_cp_1 = np.array(mses_cp_1)
    
    stacked_arrays_CP = np.vstack((mses_cp_0, mses_cp_1))
    
    mean_values_CP = np.mean(stacked_arrays_CP, axis=0)
    std_devs_CP = np.std(stacked_arrays_CP, axis=0)


    fig, ax = plt.subplots(1, 1,figsize=(10,6))
    ax.errorbar(range(len(mean_values_UN)), mean_values_UN, yerr=std_devs_UN, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Uncompressed')
    ax.errorbar(range(len(mean_values_CP)), mean_values_CP, yerr=std_devs_CP, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='CPD')   
    ax.set_title(f'Validation loss with SGD optimizer for uncompressed and CP-decomposed models.')
    ax.set_xlabel('epochs')
    ax.set_ylabel('loss')
    # plt.xticks()
    ax.set_yscale('log')
    ax.legend()
    plt.show()



def exp1():
    basic_0 = np.array([0.03736463669789384, 0.014153563749240811, 0.0073855634661047906, 0.0046002559609311525, 0.003190418394948789, 0.0022814328350302788, 0.0017258570734619263, 0.0013972283397231475, 0.001174561994489717, 0.00103729830888279, 0.0008910269722747262, 0.0008065654830953404, 0.0007396493775536324, 0.0006884797364091041, 0.0006326977452324863, 0.000605546480637727, 0.0005872123106404602, 0.000570658244766026, 0.0005511296197234076, 0.0005305801043785657, 0.0005065107053424067, 0.0004965342289852064, 0.00047633443475139897, 0.0004607110496096068, 0.000449251176143498]) 
    basic_1 = np.array([0.05341234262436044, 0.021437442350761563, 0.010998913595559687, 0.008643085822317313, 0.005353116247426234, 0.003977102227890778, 0.0031791443086245682, 0.002539163017137742, 0.0019777621183100576, 0.0016632301672921065, 0.0014399570301569962, 0.001274027357756454, 0.001061650462943081, 0.0009341617039070063, 0.0008078947552025131, 0.0007689720929546907, 0.0007444332589941747, 0.0007144555706435262, 0.0006914341053926818, 0.0006635838677547556, 0.0006467346293559308, 0.000618876643670594, 0.0005996615731875828, 0.0005841907350718223, 0.0005580332683631755])

    unet_0 = np.array([0.0034919320885059297, 0.0011850107090801058, 0.0005903145157970777, 0.00036607268664633804, 0.0002642137196081375, 0.00019889625317582248, 0.00015764943784087092, 0.00013460629506964797, 0.00013171952203051506, 9.02432395890261e-05, 7.621552250495349e-05, 8.614575960231441e-05, 5.107021814021407e-05, 5.4111266604487e-05, 5.9375571250142363e-05, 3.315692410993867e-05, 3.808538757927869e-05, 3.4124390307362785e-05, 3.07765902216209e-05, 2.8094488516451435e-05, 2.7705194027119604e-05, 2.9308312689615433e-05, 2.7121326173362486e-05, 2.5582616063837013e-05, 2.802141882258822e-05])
    unet_1 = np.array([0.0033136480685442148, 0.0009874475868714128, 0.0005265841308176546, 0.00034365540186536114, 0.0002531041917915764, 0.0002462561574572567, 0.0001436314490090976, 0.00012217584281625264, 0.00010582042010261134, 7.940147119707754e-05, 6.288277784413372e-05, 6.0825926358483724e-05, 5.5971804339935e-05, 4.756700584265344e-05, 6.261507272184582e-05, 4.23765958399965e-05, 3.8272192165012285e-05, 3.6915535356110884e-05, 3.619171903776589e-05, 3.130979687466718e-05, 3.191267324789859e-05, 2.881786170322193e-05, 3.05960344740848e-05, 3.090431628936643e-05, 2.6166022616576844e-05])

    convnext_0 = np.array([0.019204623451953912, 0.023473807076166635, 0.03370495728828585, 0.01704751179512284, 0.07325010985326257, 0.016327544318960045, 0.05223532690690449, 0.024200882617166703, 0.017666210545809493, 0.01577941614435536, 0.015904303509021046, 0.016888299718156256, 0.015803586971172894, 0.01575232568174756, 0.01583616017198883, 0.015725802773726576, 0.015729657124053675, 0.015803713344889177, 0.015718941590194907, 0.015728832486533284, 0.01583419124693823, 0.015894921012279486, 0.015738375447094947, 0.0157538658035684, 0.015720066524790754])
    # convnext_1 = np.array([0.018813866406632032, 0.09257339782750655, 0.016368748782017287, 0.01621797280119406, 0.016168704489286912, 0.024035829642554487, 0.025696859596251443, 0.024531052353561584, 0.016083052096755462, 0.01713477386231601, 0.01789484171739676, 0.02236264597692384, 0.015847910066773472, 0.01577893419034939, 0.016340680017809073, 0.01579564748439996, 0.01573954474606541, 0.015791755029034536, 0.01577505134854311, 0.015906218892322105, 0.015775148217598105, 0.015757806633334655, 0.01572518491452286, 0.016002668601290546, 0.015859029891759413])
    convnext_1 = np.array([0.4180935, 0.1561054, 0.0555688, 0.0301291, 0.0268757, 0.0267306, 0.0267293,
            0.0267294, 0.0267293, 0.0267293, 0.0267293, 0.0267293, 0.0267295, 0.0267293,
            0.0267293, 0.0267295, 0.0267301, 0.0267293, 0.0267294, 0.0267298, 0.0267294,
            0.0267294, 0.0267297, 0.0267293, 0.0267295])

    resnet_0 = np.array([0.00857887827313696, 0.006479259658306654, 0.005318269788416778, 0.0046736705533315034, 0.004118694677448741, 0.00363155662904494, 0.0033709874751239686, 0.0032716298675274855, 0.0031383955116752018, 0.0028532135504768944, 0.0027730143783216902, 0.0030116750032084666, 0.002759685047654625, 0.002611140534617131, 0.002567617829837031, 0.002410712105696461, 0.0024110207719680466, 0.002387456851006545, 0.0023404845928131604, 0.002345497057977522, 0.002327590273706729, 0.002302202574225171, 0.0022778256615429574, 0.0022564832666609495, 0.0022714197942937456])
    resnet_1 = np.array([0.008606598472597135, 0.006485292488762429, 0.005294214668926123, 0.004517744946766747, 0.004085026929728609, 0.003659280914091869, 0.0032868173859669685, 0.0031075269827141347, 0.002949891290808209, 0.0028226870402147074, 0.0026811777510900967, 0.0026557742043317005, 0.0027022214726303154, 0.0025463256830174064, 0.002616475196244398, 0.002348482823465101, 0.0023414470846034223, 0.0023132750765770785, 0.002323945712392721, 0.0022766120214577626, 0.0022791860812317643, 0.0022631961872736066, 0.002242948458144816, 0.0022726606433194465, 0.002226474344373271])
    
    
    basic = np.vstack((basic_0, basic_1))
    unet = np.vstack((unet_0, unet_1))
    convnext = np.vstack((convnext_0, convnext_1))
    resnet = np.vstack((resnet_0, resnet_1))
    
    mean_values_basic = np.mean(basic, axis=0)
    std_devs_basic = np.std(basic, axis=0)
    mean_values_unet = np.mean(unet, axis=0)
    std_devs_unet = np.std(unet, axis=0)
    mean_values_convnext = np.mean(convnext, axis=0)
    std_devs_convnext = np.std(convnext, axis=0)
    mean_values_resnet = np.mean(resnet, axis=0)
    std_devs_resnet = np.std(resnet, axis=0)
    

    fig, ax = plt.subplots(1, 1,figsize=(10,6))
    ax.errorbar(range(len(mean_values_basic)), mean_values_basic, yerr=std_devs_basic, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='royalblue', ecolor='cornflowerblue', label='Basic')
    ax.errorbar(range(len(mean_values_resnet)), mean_values_resnet, yerr=std_devs_resnet, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkorange', ecolor='orange', label='ResNet')   
    ax.errorbar(range(len(mean_values_convnext)), mean_values_convnext, yerr=std_devs_convnext, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkgreen', ecolor='green', label='ConvNeXt')   
    ax.errorbar(range(len(mean_values_unet)), mean_values_unet, yerr=std_devs_unet, fmt='-o', capsize=5, capthick=2, elinewidth=1, color='darkred', ecolor='red', label='U-Net')   
    ax.set_title(f'Validation loss with Adam optimizer for basic, ResNet, ConvNeXt and U-Net models.')
    ax.set_xlabel('epochs')
    ax.set_ylabel('loss')
    # plt.xticks()
    ax.set_yscale('log')
    ax.legend()
    plt.show()


if __name__ == '__main__':
    # plot_compression_cp()
    # plot_accs_cp()
    # data_eff()
    # exp1()
    # 2.2
    # MSE_conv()
    # convergence()
    # exp2_2_SGD()
    # 2.3
    # data_eff_0025_un()
    # data_eff_005_un()
    # data_eff_01_un()
    # data_eff_02_un()
    # data_eff_0025_cp()
    # data_eff_005_cp()
    # data_eff_01_cp()
    # data_eff_02_cp()
    exp2_3_mses()
    # exp2_3_accs()
    # plot_mses_cp()
    # plot_adam_loss()
    # plot_sgd_loss()
    # classifier_adam_vs_sgd()
    # sgd_vs_adam_loss()
    # exp1_val_comp()
    # train_val_loss('Basic')
